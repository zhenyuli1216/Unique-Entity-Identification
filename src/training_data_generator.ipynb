{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/geotargets-2020-03-03.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UK data df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_abbr = pd.read_excel('../data/abbr.xlsx', sheet_name = 'uk')\n",
    "uk_abbr_map = dict(zip(uk_abbr['Country'], uk_abbr['Abbreviation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbr_map(x, map_dict): #input a cell with state\n",
    "    x[1] = map_dict[x[1]]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[(df['Country Code']=='GB') & (df['Target Type'] == 'City') & (df['Status'] == 'Active')]\n",
    "df_1 = df_1.reset_index(drop = True)\n",
    "\n",
    "df_1['name_split_0'] = df_1['Canonical Name'].apply(lambda x: x.split(','))\n",
    "df_1['name_split_0'] = df_1['name_split_0'].apply(lambda x: x[1:] if len(x)>3 else x)\n",
    "df_1['name_split_1'] = df_1['name_split_0'].apply(lambda x: [x[0], x[-1]])\n",
    "df_1['name_split_2'] = df_1['name_split_1'].apply(lambda x: x[:-1]+['UK'])\n",
    "df_1['name_split_3'] = df_1['name_split_0'].apply(lambda x: x[:-1]+['UK'])\n",
    "df_1['name_split_4'] = df_1['name_split_1'].apply(lambda x: x[:-1]+['GB'])\n",
    "df_1['name_split_5'] = df_1['name_split_0'].apply(lambda x: x[:-1]+['GB'])\n",
    "df_1['name_split_6'] = df_1['name_split_0'].apply(lambda x: [x[0], 'Great Britain'])\n",
    "df_1['name_split_7'] = df_1['name_split_0'].apply(lambda x: x[:-1])\n",
    "df_1['name_split_8'] = df_1['name_split_0'].apply(lambda x: abbr_map(x, uk_abbr_map))\n",
    "df_1['name_split_9'] = df_1['name_split_3'].apply(lambda x: abbr_map(x, uk_abbr_map))\n",
    "df_1['name_split_10'] = df_1['name_split_5'].apply(lambda x: abbr_map(x, uk_abbr_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(split_type_length, dataframe): \n",
    "    col_select = list(range(0,split_type_length+1))\n",
    "    str_1_list = []\n",
    "    str_2_list = []\n",
    "    for idx, row in dataframe.iterrows(): \n",
    "        split_type = random.sample(col_select, 2)\n",
    "        if type(row['name_split_'+str(split_type[0])]) == list: \n",
    "                str_1_list.append(', '.join(row['name_split_'+str(split_type[0])]))\n",
    "                str_2_list.append(', '.join(row['name_split_'+str(split_type[1])]))\n",
    "        else: \n",
    "                str_1_list.append(row['name_split_'+str(split_type[0])])\n",
    "                str_2_list.append(row['name_split_'+str(split_type[1])])                  \n",
    "    return str_1_list, str_2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_1 = pd.DataFrame(columns = ['str_1', 'str_2'])\n",
    "uk = get_combinations(10, df_1)\n",
    "all_df_1['str_1'] = uk[0]\n",
    "all_df_1['str_2'] = uk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_2 = pd.DataFrame(columns = ['str_1', 'str_2'])\n",
    "uk = get_combinations(10, df_1)\n",
    "all_df_2['str_1'] = uk[0]\n",
    "all_df_2['str_2'] = uk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_1 = pd.concat([all_df_1, all_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_1 = shuffle(all_df_1)\n",
    "all_df_1 = all_df_1.head(1000)\n",
    "all_df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg(current_df, num_neg, str_1_length): \n",
    "    current_df = current_df.reset_index(drop = True)\n",
    "    neg_df_return = pd.DataFrame(columns = ['str_1', 'str_2'])\n",
    "    neg_sample = random.sample(list(current_df.index), str_1_length)\n",
    "    for idx in neg_sample: \n",
    "        temp_neg_df = pd.DataFrame(columns = ['str_1', 'str_2'])\n",
    "        temp_str_1 = current_df.drop([idx])['str_1']\n",
    "        temp_str_1 = shuffle(temp_str_1).head(str_1_length)\n",
    "        temp_str_2 = current_df.iat[idx, 1]\n",
    "        temp_neg_df['str_1'] = temp_str_1\n",
    "        temp_neg_df['str_2'] = temp_str_2\n",
    "        neg_df_return = pd.concat([neg_df_return, temp_neg_df])\n",
    "    neg_df_return['Y'] = 0\n",
    "    return neg_df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df_1 = generate_neg(all_df_1, 10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US data df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[(df['Country Code']=='US') & (df['Target Type'] == 'City') & (df['Status'] == 'Active')]\n",
    "df_2 = df_2.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_abbr = pd.read_excel('../data/abbr.xlsx', sheet_name = 'us')\n",
    "us_abbr_map = dict(zip(us_abbr['state'], us_abbr['abbr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['name_split_0'] = df_2['Canonical Name'].apply(lambda x: x.split(','))\n",
    "df_2['name_split_0'] = df_2['name_split_0'].apply(lambda x: x[1:] if len(x)>3 else x)\n",
    "df_2['name_split_1'] = df_2['Canonical Name'].apply(lambda x: x.split(','))\n",
    "df_2['name_split_1'] = df_2['name_split_1'].apply(lambda x: x[1:] if len(x)>3 else x)\n",
    "df_2['name_split_1'] = df_2['name_split_1'].apply(lambda x: x[:-1]+['US'])\n",
    "df_2['name_split_2'] = df_2['name_split_1'].apply(lambda x: x[:-1]+['USA'])\n",
    "df_2['name_split_3'] = df_2.apply(lambda x: x['name_split_2'][:-1], axis = 1)\n",
    "df_2['name_split_4'] = df_2['name_split_2'].apply(lambda x: abbr_map(x, us_abbr_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['name_split_4'] = df_2.apply(lambda x: x['name_split_4'][:-1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_2 = pd.DataFrame(columns = ['str_1', 'str_2'])\n",
    "us = get_combinations(4, df_2)\n",
    "all_df_2['str_1'] = us[0]\n",
    "all_df_2['str_2'] = us[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_2 = shuffle(all_df_2).head(1000)\n",
    "all_df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df_2 = generate_neg(all_df_2, 5, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company name df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOCK_1 = pd.read_csv('../data/MOCK_DATA_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = MOCK_1[['company_name']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df['name_split_0'] = comp_df['company_name'].apply(lambda x: x.upper())\n",
    "comp_df['ending'] = comp_df['name_split_0'].apply(lambda x: x.split()[-1])\n",
    "comp_df['start'] = comp_df['name_split_0'].apply(lambda x: x.split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dict = {'CORPORATION': 'Corp.', 'TRUST': 'Tr.', 'DIVIDEND': 'DIV', 'INC.': 'Incorporated', \\\n",
    "             'BANK': 'BK', 'CORP.': 'Corporation','Incorporated': 'Inc.', 'BANCORP': 'Corporation', \\\n",
    "            'LTD.': 'Limited', 'L.P.': 'Limited Partnership', 'BANCORP.': 'Corporation', \\\n",
    "            'LIMITED': 'Ltd.', 'GROUP': 'Association', 'LTD': 'LIMITED', 'CO.': 'Company'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df['name_split_1'] = comp_df['name_split_0'].apply(lambda x: x.replace('&', ' and '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df['replace'] = comp_df['ending'].map(comp_dict)\n",
    "comp_df['replace'] = comp_df['replace'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df['name_split_2'] = comp_df.apply(lambda row: row['start']+[row['replace']], axis = 1)\n",
    "comp_df['name_split_2'] = comp_df['name_split_2'].apply(lambda x: ' '.join(x))\n",
    "comp_df['name_split_3'] = comp_df['name_split_2'].apply(lambda x: x.replace('&', ' and '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_3 = pd.DataFrame(columns = ['str_1', 'str_2'])\n",
    "company = get_combinations(3, comp_df)\n",
    "all_df_3['str_1'] = company[0]\n",
    "all_df_3['str_2'] = company[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df_3 = generate_neg(all_df_3, 20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>str_1</th>\n",
       "      <th>str_2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TELEPHONE AND DATA SYSTEMS, INC.</td>\n",
       "      <td>CATERPILLAR, INC.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>WESTERN ASSET/CLAYMORE U.S TREASURY INFLATION ...</td>\n",
       "      <td>CATERPILLAR, INC.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>ACLARIS THERAPEUTICS, Incorporated</td>\n",
       "      <td>CATERPILLAR, INC.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JENSYN ACQUISTION CORP.</td>\n",
       "      <td>CATERPILLAR, INC.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>WESTERN ASSET EMERGING MARKETS DEBT FUND INC</td>\n",
       "      <td>CATERPILLAR, INC.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>TELEPHONE AND DATA SYSTEMS, INC.</td>\n",
       "      <td>DLH HOLDINGS Corporation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>WASHINGTON TRUST BANCORP, Incorporated</td>\n",
       "      <td>DLH HOLDINGS Corporation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>PROTO LABS, INC.</td>\n",
       "      <td>DLH HOLDINGS Corporation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>AUTODESK, Incorporated</td>\n",
       "      <td>DLH HOLDINGS Corporation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>PROVIDENT FINANCIAL SERVICES, INC</td>\n",
       "      <td>DLH HOLDINGS Corporation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 str_1  \\\n",
       "35                    TELEPHONE AND DATA SYSTEMS, INC.   \n",
       "492  WESTERN ASSET/CLAYMORE U.S TREASURY INFLATION ...   \n",
       "110                 ACLARIS THERAPEUTICS, Incorporated   \n",
       "9                              JENSYN ACQUISTION CORP.   \n",
       "225       WESTERN ASSET EMERGING MARKETS DEBT FUND INC   \n",
       "..                                                 ...   \n",
       "765                   TELEPHONE AND DATA SYSTEMS, INC.   \n",
       "826             WASHINGTON TRUST BANCORP, Incorporated   \n",
       "558                                   PROTO LABS, INC.   \n",
       "707                             AUTODESK, Incorporated   \n",
       "581                  PROVIDENT FINANCIAL SERVICES, INC   \n",
       "\n",
       "                        str_2  Y  \n",
       "35          CATERPILLAR, INC.  0  \n",
       "492         CATERPILLAR, INC.  0  \n",
       "110         CATERPILLAR, INC.  0  \n",
       "9           CATERPILLAR, INC.  0  \n",
       "225         CATERPILLAR, INC.  0  \n",
       "..                        ... ..  \n",
       "765  DLH HOLDINGS Corporation  0  \n",
       "826  DLH HOLDINGS Corporation  0  \n",
       "558  DLH HOLDINGS Corporation  0  \n",
       "707  DLH HOLDINGS Corporation  0  \n",
       "581  DLH HOLDINGS Corporation  0  \n",
       "\n",
       "[900 rows x 3 columns]"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US address df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = MOCK_1[['address', 'state', 'state_abbr']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a city/ town name for each location\n",
    "locations = df_2['Canonical Name'].tolist()\n",
    "locations = [x.split(',')[0] for x in locations]\n",
    "locations = random.sample(locations, 1000)\n",
    "df_4['city'] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get postal code for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['street_type'] = df_4['address'].apply(lambda x: x.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_dict = {'Point':'Pt', 'Drive':'Dr', 'Junction':'Jct', 'Court':'Ct', 'Lane':'Ln', 'Street':'St', 'Avenue':'Av',\n",
    "       'Way':'Way', 'Trail':'Trl', 'Terrace':'Ter', 'Center':'Ctr', 'Crossing':'XING', 'Park':'Park', 'Road':'Rd',\n",
    "       'Circle':'Cir', 'Pass':'Pass', 'Parkway':'Pkwy', 'Hill':'Hl', 'Place':'Pl', 'Alley':'Aly', 'Plaza':'Plz'}\n",
    "df_4['street_type_abbr'] = df_4['street_type'].map(street_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address_2(row): \n",
    "    address = row['address'].split()\n",
    "    address[2] = row['street_type_abbr']\n",
    "    return ' '.join(address)\n",
    "df_4['address_2'] = df_4.apply(lambda row: get_address_2(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['name_split_0'] = df_4['address']+', '+df_4['city']+', '+df_4['state']\n",
    "df_4['name_split_1'] = df_4['address_2']+', '+df_4['city']+', '+df_4['state']\n",
    "df_4['name_split_2'] = df_4['address']+', '+df_4['city']+', '+df_4['state_abbr']\n",
    "df_4['name_split_3'] = df_4['address_2']+', '+df_4['city']+', '+df_4['state_abbr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = list(range(0, 10))*5\n",
    "postal = []\n",
    "for i in range(0, 1000): \n",
    "    p = [str(x) for x in random.sample(code, 5)]\n",
    "    postal.append(''.join(p))\n",
    "df_4['postal_code'] = postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4['name_split_4'] = df_4['name_split_1']+' '+df_4['postal_code']\n",
    "df_4['name_split_5'] = df_4['name_split_2']+' '+df_4['postal_code']\n",
    "df_4['name_split_6'] = df_4['name_split_3']+' '+df_4['postal_code']\n",
    "df_4['name_split_7'] = df_4['name_split_4']+', USA'\n",
    "df_4['name_split_8'] = df_4['name_split_5']+', USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_4 = pd.DataFrame()\n",
    "all_df_4_2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_1 = get_combinations(8, df_4)\n",
    "all_df_4['str_1'] = gen_1[0]\n",
    "all_df_4['str_2'] = gen_1[1]\n",
    "\n",
    "gen_2 = get_combinations(8, df_4)\n",
    "all_df_4_2['str_1'] = gen_1[0]\n",
    "all_df_4_2['str_2'] = gen_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_4 = pd.concat([all_df_4, all_df_4_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df_4 = generate_neg(all_df_4, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>str_1</th>\n",
       "      <th>str_2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>6379 Cottonwood Pt, Baxter, LA</td>\n",
       "      <td>071 Anniversary Crossing, Ross, Florida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>86 Vermont Park, Elgin, LA 19187</td>\n",
       "      <td>071 Anniversary Crossing, Ross, Florida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>3946 Dexter Terrace, Spring Arbor, LA 58680, USA</td>\n",
       "      <td>071 Anniversary Crossing, Ross, Florida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>3 Hauk Hl, Blackwater, TX</td>\n",
       "      <td>071 Anniversary Crossing, Ross, Florida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>9513 Grover Terrace, Mitchell, NC 58255, USA</td>\n",
       "      <td>071 Anniversary Crossing, Ross, Florida</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>69195 Coolidge Center, Lucerne, KS</td>\n",
       "      <td>8400 5th Rd, Elbow Lake, LA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>384 Logan Pkwy, Lecanto, IL</td>\n",
       "      <td>8400 5th Rd, Elbow Lake, LA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>8968 Luster Dr, Abbeville, Florida 78221, USA</td>\n",
       "      <td>8400 5th Rd, Elbow Lake, LA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>11 Melby Trl, Floyds Knobs, IL</td>\n",
       "      <td>8400 5th Rd, Elbow Lake, LA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>8928 Graceland Park, Anna, Georgia</td>\n",
       "      <td>8400 5th Rd, Elbow Lake, LA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 str_1  \\\n",
       "1882                    6379 Cottonwood Pt, Baxter, LA   \n",
       "1839                  86 Vermont Park, Elgin, LA 19187   \n",
       "964   3946 Dexter Terrace, Spring Arbor, LA 58680, USA   \n",
       "812                          3 Hauk Hl, Blackwater, TX   \n",
       "1142      9513 Grover Terrace, Mitchell, NC 58255, USA   \n",
       "...                                                ...   \n",
       "1402                69195 Coolidge Center, Lucerne, KS   \n",
       "1785                       384 Logan Pkwy, Lecanto, IL   \n",
       "520      8968 Luster Dr, Abbeville, Florida 78221, USA   \n",
       "553                     11 Melby Trl, Floyds Knobs, IL   \n",
       "1273                8928 Graceland Park, Anna, Georgia   \n",
       "\n",
       "                                        str_2  Y  \n",
       "1882  071 Anniversary Crossing, Ross, Florida  0  \n",
       "1839  071 Anniversary Crossing, Ross, Florida  0  \n",
       "964   071 Anniversary Crossing, Ross, Florida  0  \n",
       "812   071 Anniversary Crossing, Ross, Florida  0  \n",
       "1142  071 Anniversary Crossing, Ross, Florida  0  \n",
       "...                                       ... ..  \n",
       "1402              8400 5th Rd, Elbow Lake, LA  0  \n",
       "1785              8400 5th Rd, Elbow Lake, LA  0  \n",
       "520               8400 5th Rd, Elbow Lake, LA  0  \n",
       "553               8400 5th Rd, Elbow Lake, LA  0  \n",
       "1273              8400 5th Rd, Elbow Lake, LA  0  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UK address df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOCK_2 = pd.read_csv('../data/MOCK_DATA_2.csv')\n",
    "df_5 = MOCK_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a city/ town name for each locatio\n",
    "locations = df_1['Canonical Name'].tolist()\n",
    "locations = [x.split(',')[0] for x in locations]\n",
    "locations_1 = random.sample(locations, 900)\n",
    "locations_2 = random.sample(locations, 100)\n",
    "locations = locations_1+locations_2\n",
    "df_5['city'] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5['street_type'] = df_5['address'].apply(lambda x: x.split()[-1])\n",
    "df_5['street_type_abbr'] = df_5['street_type'].map(street_dict)\n",
    "df_5['address_2'] = df_5.apply(lambda row: get_address_2(row), axis = 1)\n",
    "df_5['name_split_0'] = df_5['address']+', '+df_5['city']+', '+df_5['state']\n",
    "df_5['name_split_1'] = df_5['address_2']+', '+df_5['city']+', '+df_5['state']\n",
    "df_5['name_split_2'] = df_5['address']+', '+df_5['city']+', '+df_5['state_abbr']\n",
    "df_5['name_split_3'] = df_5['address_2']+', '+df_5['city']+', '+df_5['state_abbr']\n",
    "df_5['name_split_4'] = df_5['name_split_1']+', '+df_5['postal_code']\n",
    "df_5['name_split_5'] = df_5['name_split_2']+', '+df_5['postal_code']\n",
    "df_5['name_split_6'] = df_5['name_split_3']+', '+df_5['postal_code']\n",
    "df_5['name_split_7'] = df_5['name_split_4']+', GB'\n",
    "df_5['name_split_8'] = df_5['name_split_5']+', UK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_5 = pd.DataFrame()\n",
    "all_df_5_2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_1 = get_combinations(8, df_5)\n",
    "all_df_5['str_1'] = gen_1[0]\n",
    "all_df_5['str_2'] = gen_1[1]\n",
    "\n",
    "gen_2 = get_combinations(8, df_5)\n",
    "all_df_5_2['str_1'] = gen_1[0]\n",
    "all_df_5_2['str_2'] = gen_1[1]\n",
    "\n",
    "all_df_5 = pd.concat([all_df_5, all_df_5_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df_5 = generate_neg(all_df_5, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>str_1</th>\n",
       "      <th>str_2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>3972 Monument Terrace, Porthcawl, ENG, RH5, UK</td>\n",
       "      <td>03 Kingsford Drive, Borehamwood, SCT, IV1, UK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>3 Carberry Aly, Windsor, England, WC1B</td>\n",
       "      <td>03 Kingsford Drive, Borehamwood, SCT, IV1, UK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>332 Daystar Hill, Bredbury, SCT, AB39, UK</td>\n",
       "      <td>03 Kingsford Drive, Borehamwood, SCT, IV1, UK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>074 Kim Plz, Roslin, NIR</td>\n",
       "      <td>03 Kingsford Drive, Borehamwood, SCT, IV1, UK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>44 Crowley Drive, Hemel Hempstead, ENG</td>\n",
       "      <td>03 Kingsford Drive, Borehamwood, SCT, IV1, UK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>30 Acker Park, Willenhall, England, CB4, GB</td>\n",
       "      <td>92023 Debs Pl, Hexham, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>5645 Dakota Lane, Watford, ENG, M34</td>\n",
       "      <td>92023 Debs Pl, Hexham, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>52 Superior Way, Alconbury, ENG, NE46</td>\n",
       "      <td>92023 Debs Pl, Hexham, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>52 Brown Park, Oswestry, SCT, KW10</td>\n",
       "      <td>92023 Debs Pl, Hexham, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>77 Old St Street, Newry, ENG</td>\n",
       "      <td>92023 Debs Pl, Hexham, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               str_1  \\\n",
       "1669  3972 Monument Terrace, Porthcawl, ENG, RH5, UK   \n",
       "1641          3 Carberry Aly, Windsor, England, WC1B   \n",
       "55         332 Daystar Hill, Bredbury, SCT, AB39, UK   \n",
       "1719                        074 Kim Plz, Roslin, NIR   \n",
       "779           44 Crowley Drive, Hemel Hempstead, ENG   \n",
       "...                                              ...   \n",
       "1825     30 Acker Park, Willenhall, England, CB4, GB   \n",
       "251              5645 Dakota Lane, Watford, ENG, M34   \n",
       "636            52 Superior Way, Alconbury, ENG, NE46   \n",
       "692               52 Brown Park, Oswestry, SCT, KW10   \n",
       "1674                    77 Old St Street, Newry, ENG   \n",
       "\n",
       "                                              str_2  Y  \n",
       "1669  03 Kingsford Drive, Borehamwood, SCT, IV1, UK  0  \n",
       "1641  03 Kingsford Drive, Borehamwood, SCT, IV1, UK  0  \n",
       "55    03 Kingsford Drive, Borehamwood, SCT, IV1, UK  0  \n",
       "1719  03 Kingsford Drive, Borehamwood, SCT, IV1, UK  0  \n",
       "779   03 Kingsford Drive, Borehamwood, SCT, IV1, UK  0  \n",
       "...                                             ... ..  \n",
       "1825                 92023 Debs Pl, Hexham, England  0  \n",
       "251                  92023 Debs Pl, Hexham, England  0  \n",
       "636                  92023 Debs Pl, Hexham, England  0  \n",
       "692                  92023 Debs Pl, Hexham, England  0  \n",
       "1674                 92023 Debs Pl, Hexham, England  0  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative samples, concat and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([all_df_1, all_df_2, all_df_3, all_df_4, all_df_5])\n",
    "all_df['Y'] = 1\n",
    "all_df = all_df[all_df['str_1']!=all_df['str_2']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>str_1</th>\n",
       "      <th>str_2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen, SCT, UK</td>\n",
       "      <td>Aberdeen, SCT, United Kingdom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kidderminster, GB</td>\n",
       "      <td>Kidderminster, England</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keele, ENG, GB</td>\n",
       "      <td>Keele, GB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cowes, ENG, GB</td>\n",
       "      <td>Cowes, Great Britain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gloucester, Great Britain</td>\n",
       "      <td>Gloucester, United Kingdom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>2559 Westridge Rd, Bourton, England</td>\n",
       "      <td>2559 Westridge Rd, Bourton, ENG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>5 Vidon Alley, Bury, SCT, EH9, UK</td>\n",
       "      <td>5 Vidon Alley, Bury, SCT, EH9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>782 Luster Av, Hailsham, England, LS6, GB</td>\n",
       "      <td>782 Luster Avenue, Hailsham, England</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>30 Jackson Rd, Tuxford, England, NG22, GB</td>\n",
       "      <td>30 Jackson Road, Tuxford, ENG, NG22, UK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>06870 Schiller Plz, Brill, ENG</td>\n",
       "      <td>06870 Schiller Plaza, Brill, ENG, OX12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6579 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          str_1  \\\n",
       "0                             Aberdeen, SCT, UK   \n",
       "1                             Kidderminster, GB   \n",
       "2                                Keele, ENG, GB   \n",
       "3                                Cowes, ENG, GB   \n",
       "4                     Gloucester, Great Britain   \n",
       "...                                         ...   \n",
       "6574        2559 Westridge Rd, Bourton, England   \n",
       "6575          5 Vidon Alley, Bury, SCT, EH9, UK   \n",
       "6576  782 Luster Av, Hailsham, England, LS6, GB   \n",
       "6577  30 Jackson Rd, Tuxford, England, NG22, GB   \n",
       "6578             06870 Schiller Plz, Brill, ENG   \n",
       "\n",
       "                                        str_2  Y  \n",
       "0               Aberdeen, SCT, United Kingdom  1  \n",
       "1                      Kidderminster, England  1  \n",
       "2                                   Keele, GB  1  \n",
       "3                        Cowes, Great Britain  1  \n",
       "4                  Gloucester, United Kingdom  1  \n",
       "...                                       ... ..  \n",
       "6574          2559 Westridge Rd, Bourton, ENG  1  \n",
       "6575            5 Vidon Alley, Bury, SCT, EH9  1  \n",
       "6576     782 Luster Avenue, Hailsham, England  1  \n",
       "6577  30 Jackson Road, Tuxford, ENG, NG22, UK  1  \n",
       "6578   06870 Schiller Plaza, Brill, ENG, OX12  1  \n",
       "\n",
       "[6579 rows x 3 columns]"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = generate_neg(all_df, 30, 100)\n",
    "\n",
    "df_train = pd.concat([all_df, neg_df])\n",
    "df_train = shuffle(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>str_1</th>\n",
       "      <th>str_2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>71 Magdeline Dr, Runcorn, ENG</td>\n",
       "      <td>3 Jenifer Pkwy, Converse, Florida 11398, USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Northwich, United Kingdom</td>\n",
       "      <td>3 Jenifer Pkwy, Converse, Florida 11398, USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Climax Springs, Missouri, United States</td>\n",
       "      <td>3 Jenifer Pkwy, Converse, Florida 11398, USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>5869 Buhler Dr, Rutland, Texas</td>\n",
       "      <td>3 Jenifer Pkwy, Converse, Florida 11398, USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>91028 5th Rd, Rustington, England</td>\n",
       "      <td>3 Jenifer Pkwy, Converse, Florida 11398, USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>91173 Carioca XING, Tonbridge, ENG, BS41</td>\n",
       "      <td>271 Bluejay Center, Coatbridge, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>4283 Brown Plz, Chesnee, Virginia 26271</td>\n",
       "      <td>271 Bluejay Center, Coatbridge, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Oldbury, ENG, GB</td>\n",
       "      <td>271 Bluejay Center, Coatbridge, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>6 Sauthoff Lane, Wombwell, ENG</td>\n",
       "      <td>271 Bluejay Center, Coatbridge, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Hastingwood, ENG, United Kingdom</td>\n",
       "      <td>271 Bluejay Center, Coatbridge, England</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         str_1  \\\n",
       "4839             71 Magdeline Dr, Runcorn, ENG   \n",
       "503                  Northwich, United Kingdom   \n",
       "1758   Climax Springs, Missouri, United States   \n",
       "2624            5869 Buhler Dr, Rutland, Texas   \n",
       "5498         91028 5th Rd, Rustington, England   \n",
       "...                                        ...   \n",
       "6032  91173 Carioca XING, Tonbridge, ENG, BS41   \n",
       "3932   4283 Brown Plz, Chesnee, Virginia 26271   \n",
       "733                           Oldbury, ENG, GB   \n",
       "5483            6 Sauthoff Lane, Wombwell, ENG   \n",
       "588           Hastingwood, ENG, United Kingdom   \n",
       "\n",
       "                                             str_2  Y  \n",
       "4839  3 Jenifer Pkwy, Converse, Florida 11398, USA  0  \n",
       "503   3 Jenifer Pkwy, Converse, Florida 11398, USA  0  \n",
       "1758  3 Jenifer Pkwy, Converse, Florida 11398, USA  0  \n",
       "2624  3 Jenifer Pkwy, Converse, Florida 11398, USA  0  \n",
       "5498  3 Jenifer Pkwy, Converse, Florida 11398, USA  0  \n",
       "...                                            ... ..  \n",
       "6032       271 Bluejay Center, Coatbridge, England  0  \n",
       "3932       271 Bluejay Center, Coatbridge, England  0  \n",
       "733        271 Bluejay Center, Coatbridge, England  0  \n",
       "5483       271 Bluejay Center, Coatbridge, England  0  \n",
       "588        271 Bluejay Center, Coatbridge, England  0  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_neg_df = pd.concat([neg_df_1, neg_df_2, neg_df_3, neg_df_4, neg_df_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, other_neg_df])\n",
    "df_train = shuffle(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3448293935740867"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Y'].sum()/df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/traning_v5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
