{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from nltk.corpus import stopwords \n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn import preprocessing\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from scipy.cluster import  hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained Word2Vec and sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = api.load(\"word2vec-google-news-300\", return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(model_path, binary= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized model so we can use wmdistance later\n",
    "w2v_norm = KeyedVectors.load_word2vec_format(model_path, binary= True)\n",
    "w2v_norm.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marks and Spencers Ltd', 'M&S Limited', 'NVIDIA Ireland', 'SLOUGH SE12 2XY', '33 TIMBER YARD,LONDON, L1 8XY', '44 CHINA ROAD, KOWLOON, HONG KONG', 'XYZ 13423 / ILD', 'ABC/ICL/20891NC', 'HARDWOOD TABLE', 'PLASTIC BOTTLE', 'LONDON', 'HONG KONG', 'ASIA', 'JP Morgan & Chase Co.', 'ICNAO02312', 'TOYS', '5 Time Square, New York, NY 10036', 'COMPUTER PARTS', 'INTEL CORPORATION', 'INTEL CO', 'Ryland Group Inc.', 'Sabre Holdings Corp', 'Safeco Corp', '4CE0460D0G', 'Vero Beach, Florida', 'WINE', 'Microwave', 'Plastic container', 'Europe', 'Canada', 'HGU6UH3']\n"
     ]
    }
   ],
   "source": [
    "with open('../data/data.txt', 'r') as f: \n",
    "    data = f.readlines()\n",
    "f.close()\n",
    "data = [x.rstrip().lstrip().strip('\\\",') for x in data]\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans('', '', string.punctuation.replace('#', '').replace('&', ''))\n",
    "stop_words = set(stopwords.words('english')) \n",
    "    # After trying different preprocessing combinations, I decided not to filter out stops words, \n",
    "    # and keept '#' and '&' since they can help defining a string in our specific case \n",
    "def get_tokens(x): \n",
    "    #print (x)\n",
    "    x = re.sub(r'\\d', '#', x).lower()\n",
    "    tokens = word_tokenize(x)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [x for x in tokens if x != '']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_token'] = df['text'].apply(lambda x: get_tokens(x))\n",
    "df['clean_string'] = df['clean_token'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram_list = [x for x in w2v.index2word if re.search('(_){1,}', x)]\n",
    "bi_gram_list_lower = [x.lower() for x in bi_gram_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bi_gram(x): \n",
    "    return_list = []\n",
    "    last_flag = False\n",
    "    for i in range(len(x)-1): \n",
    "        current_token = x[i]\n",
    "        current_bigram = x[i]+'_'+x[i+1]\n",
    "        if current_token != '#' and current_bigram in bi_gram_list_lower:\n",
    "            matched_idx = bi_gram_list_lower.index(current_bigram)\n",
    "            current_token = bi_gram_list[matched_idx]\n",
    "            if i+1 == len(x)-1: \n",
    "                last_flag = True\n",
    "        return_list.append(current_token)\n",
    "    if last_flag == False: \n",
    "        return_list.append(x[-1])\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_token_bi_gram'] = df['clean_token'].apply(lambda x: get_bi_gram(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get word2vec vectors from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vocab = w2v.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vector per string\n",
    "def get_vector(x):\n",
    "    agg_vector = []\n",
    "    for token in x: \n",
    "        if token in model_vocab: \n",
    "            v = w2v[token]  \n",
    "        elif token.capitalize() in model_vocab:\n",
    "            v = w2v[token.capitalize()] \n",
    "        else: \n",
    "            #print (token, 'NOT FOUND!')\n",
    "            v = w2v['#'] # assign unknown words (usually random letters in a serial number) to # to skew the vector\n",
    "        agg_vector.append(v)\n",
    "    agg_vector = np.array(agg_vector)\n",
    "    agg_vector = np.mean(agg_vector, axis = 0)\n",
    "    return agg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vecter_300'] = df['clean_token_bi_gram'].apply(lambda x: get_vector(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding word and character count, and a flag for possible company name\n",
    "company_str = ['corporation', 'inc', 'co', 'corp', 'cooperatives', 'ltd', 'limited', 'company', \\\n",
    "               'lp', 'incorporated', 'international', 'association']\n",
    "def get_word_cnt(x): \n",
    "    return len(x)\n",
    "\n",
    "def get_char_cnt(x): \n",
    "    return len(''.join(x))\n",
    "\n",
    "def get_company_flag(x): \n",
    "    if any(w in company_str for w in x): \n",
    "        return 1\n",
    "    else: return 0 \n",
    "    \n",
    "def get_digits_ratio(x): \n",
    "    x = x.replace(' ', '')\n",
    "    digit_count = 0\n",
    "    for c in x: \n",
    "        if c.isdigit(): \n",
    "            digit_count += 1\n",
    "    return digit_count/len(x)\n",
    "\n",
    "count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "def get_punc_ratio(x): \n",
    "    x = x.replace(' ', '')\n",
    "    punc = count(x,set(string.punctuation)) \n",
    "    return punc/len(x)\n",
    "        \n",
    "df['word_count'] = df['clean_token'].apply(lambda x: get_word_cnt(x))\n",
    "df['char_count'] = df['clean_token'].apply(lambda x: get_char_cnt(x))\n",
    "df['company_str'] = df['clean_token'].apply(lambda x: get_company_flag(x))\n",
    "df['digital_ratio'] = df['text'].apply(lambda x: get_digits_ratio(x))\n",
    "df['punctuation_ratio'] = df['text'].apply(lambda x: get_punc_ratio(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_features(row): \n",
    "    concat_list = np.array([row['word_count'], row['char_count'], row['company_str'], row['digital_ratio'], row['punctuation_ratio']])\n",
    "    new_concat_list = np.append(row['vecter_300'], concat_list)\n",
    "    return new_concat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_feature_concat'] = df.apply(lambda row: concat_features(row), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector size:  (31, 305)\n"
     ]
    }
   ],
   "source": [
    "def scale_mat(vec_matrix,preprocess_type):\n",
    "    if preprocess_type == 'MinMax':\n",
    "        scale = preprocessing.MinMaxScaler().fit(vec_matrix)  \n",
    "    if preprocess_type == 'Standard':\n",
    "        scale = preprocessing.StandardScaler().fit(vec_matrix)\n",
    "    vals = scale.transform(vec_matrix)\n",
    "    return vals\n",
    "\n",
    "vector_matrix = np.array(df['new_feature_concat'].tolist())\n",
    "vector_matrix = scale_mat(vector_matrix, 'MinMax')\n",
    "print ('vector size: ', vector_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA reduce dimensions\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "vals_pca = sklearn_pca.fit_transform(vector_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 2D array to df \n",
    "df['2D'] = vals_pca.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "data2D = np.array(df['2D'].tolist())\n",
    "n = df.index\n",
    "plt.scatter(vals_pca[:,0], vals_pca[:,1])\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (vals_pca[i,0], vals_pca[i,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are some sort of patterns forming. Some examples are: \n",
    "<br> On far right there are locations: 10(LONDON), 12(ASIA), 28(Europ), and 29(Canada) \n",
    "<br> The center cluster is mostly companies: 0(Marks and Spencers Ltd), 1(M&S Limited), 21(Sabre Holdings Corp), 13(JP Morgan & Chase Co)\n",
    "<br> The top part is mostly items, there are 8(HARDWOOD TABLE), 9(PLASTIC BOTTLE), 15(TOYS), 17(COMPUTER PARTS), 25(WINE), 26(microwave), 27(Plastic container)\n",
    "<br> On bottom left there are serial numbers: 6(XYZ 13423 / ILD), 7(ABC/ICL/20891NC), 14(ICNAO02312), 23(4CE0460D0G), 30(HGU6UH3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>clean_string</th>\n",
       "      <th>vecter_300</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>company_str</th>\n",
       "      <th>new_feature_concat</th>\n",
       "      <th>digital_ratio</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "      <th>2D</th>\n",
       "      <th>hierarchy_label</th>\n",
       "      <th>clean_token_bi_gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marks and Spencers Ltd</td>\n",
       "      <td>[marks, and, spencers, ltd]</td>\n",
       "      <td>marks and spencers ltd</td>\n",
       "      <td>[-0.081870556, -0.028320312, -0.05102539, 0.10...</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.08187055587768555, -0.0283203125, -0.05102...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.21785738628969087, -0.6526475067830879]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[marks, and, spencers, ltd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M&amp;S Limited</td>\n",
       "      <td>[m, &amp;, s, limited]</td>\n",
       "      <td>m &amp; s limited</td>\n",
       "      <td>[-0.15039062, 0.09075928, -0.11743164, 0.13623...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.150390625, 0.09075927734375, -0.1174316406...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>[-0.5241411593227774, -0.3759396544394854]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[m, &amp;, s, limited]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA Ireland</td>\n",
       "      <td>[nvidia, ireland]</td>\n",
       "      <td>nvidia ireland</td>\n",
       "      <td>[0.01928711, -0.19091797, -0.053955078, 0.3242...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.019287109375, -0.19091796875, -0.0539550781...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[2.14325646307336, 0.7570817600426596]</td>\n",
       "      <td>cluster_2</td>\n",
       "      <td>[nvidia, ireland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLOUGH SE12 2XY</td>\n",
       "      <td>[slough, se, #, #, #, xy]</td>\n",
       "      <td>slough se # # # xy</td>\n",
       "      <td>[-0.08087158, -0.079182945, 0.05058797, 0.0112...</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.08087158203125, -0.0791829451918602, 0.050...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.7947209999704078, 1.450827102862683]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[slough, se, #, #, #, xy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33 TIMBER YARD,LONDON, L1 8XY</td>\n",
       "      <td>[#, #, timber, yard, london, l, #, #, xy]</td>\n",
       "      <td># # timber yard london l # # xy</td>\n",
       "      <td>[-0.053792316, -0.05820041, -0.040527344, 0.02...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0537923164665699, -0.0582004114985466, -0....</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>[-0.6639117274922118, 1.2593845789605327]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[#, #, timber, yard, london, l, #, #, xy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44 CHINA ROAD, KOWLOON, HONG KONG</td>\n",
       "      <td>[#, #, china, road, kowloon, hong, kong]</td>\n",
       "      <td># # china road kowloon hong kong</td>\n",
       "      <td>[-0.029296875, -0.008544922, -0.027374268, 0.1...</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.029296875, -0.008544921875, -0.02737426757...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>[-0.4829997613936409, 0.1633026370875465]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[#, #, china, road, kowloon, Hong_Kong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XYZ 13423 / ILD</td>\n",
       "      <td>[xyz, #, #, #, #, #, ild]</td>\n",
       "      <td>xyz # # # # # ild</td>\n",
       "      <td>[-0.03137207, -0.16071428, 0.038007464, 0.0290...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0313720703125, -0.1607142835855484, 0.0380...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>[-1.1662113068773892, 2.038164207474194]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[xyz, #, #, #, #, #, ild]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABC/ICL/20891NC</td>\n",
       "      <td>[abcicl, #, #, #, #, #, nc]</td>\n",
       "      <td>abcicl # # # # # nc</td>\n",
       "      <td>[-0.04889788, -0.19213867, 0.03993443, 0.04035...</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0488978810608387, -0.192138671875, 0.03993...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>[-1.3660956376220394, 2.646343018784372]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[abcicl, #, #, #, #, #, nc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HARDWOOD TABLE</td>\n",
       "      <td>[hardwood, table]</td>\n",
       "      <td>hardwood table</td>\n",
       "      <td>[-0.06680298, 0.090270996, 0.015136719, 0.2207...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.066802978515625, 0.09027099609375, 0.01513...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.7936115213264696, -1.1702179552925702]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[hardwood, table]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PLASTIC BOTTLE</td>\n",
       "      <td>[plastic, bottle]</td>\n",
       "      <td>plastic bottle</td>\n",
       "      <td>[-0.21679688, -0.18652344, -0.025756836, 0.041...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.216796875, -0.1865234375, -0.0257568359375...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1.0395265178842157, -0.9673859940555555]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[Plastic_Bottle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LONDON</td>\n",
       "      <td>[london]</td>\n",
       "      <td>london</td>\n",
       "      <td>[-0.4609375, 0.027954102, -0.26757812, 0.41015...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.4609375, 0.0279541015625, -0.267578125, 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[3.520168681022658, 0.5717443397363491]</td>\n",
       "      <td>cluster_1</td>\n",
       "      <td>[london]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>[hong, kong]</td>\n",
       "      <td>hong kong</td>\n",
       "      <td>[0.008300781, -0.018798828, -0.12451172, 0.046...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.00830078125, -0.018798828125, -0.1245117187...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.4909592109840397, -1.3710826802831357]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[Hong_Kong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ASIA</td>\n",
       "      <td>[asia]</td>\n",
       "      <td>asia</td>\n",
       "      <td>[-0.15332031, 0.03112793, -0.28710938, 0.28515...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.1533203125, 0.0311279296875, -0.287109375,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[3.7243591171218737, 0.09884199626703945]</td>\n",
       "      <td>cluster_1</td>\n",
       "      <td>[asia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JP Morgan &amp; Chase Co.</td>\n",
       "      <td>[jp, morgan, &amp;, chase, co]</td>\n",
       "      <td>jp morgan &amp; chase co</td>\n",
       "      <td>[-0.11416016, 0.0953125, -0.14238282, 4.882812...</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.11416015774011612, 0.09531249850988388, -0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>[-0.2773023301133141, -0.7386944469461296]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[JP_Morgan, morgan, &amp;, chase, co]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ICNAO02312</td>\n",
       "      <td>[icnao, #, #, #, #, #]</td>\n",
       "      <td>icnao # # # # #</td>\n",
       "      <td>[-0.033447266, -0.21972656, 0.01940918, 0.0081...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.033447265625, -0.2197265625, 0.01940917968...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1.6535629629423227, 2.806075337716592]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[icnao, #, #, #, #, #]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TOYS</td>\n",
       "      <td>[toys]</td>\n",
       "      <td>toys</td>\n",
       "      <td>[0.1484375, 0.17675781, 0.15527344, 0.38085938...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1484375, 0.1767578125, 0.1552734375, 0.3808...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.7848783343063905, -2.7075351850596334]</td>\n",
       "      <td>cluster_4</td>\n",
       "      <td>[toys]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5 Time Square, New York, NY 10036</td>\n",
       "      <td>[#, time, square, new, york, ny, #, #, #, #, #]</td>\n",
       "      <td># time square new york ny # # # # #</td>\n",
       "      <td>[-0.09442694, -0.09439616, -0.005909313, 0.031...</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.09442693740129471, -0.09439615905284882, -...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>[-0.8641564055279805, 1.5423187370434204]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[#, time, square, New_York, york, ny, #, #, #,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COMPUTER PARTS</td>\n",
       "      <td>[computer, parts]</td>\n",
       "      <td>computer parts</td>\n",
       "      <td>[0.123046875, -0.018066406, 0.12792969, 0.1962...</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.123046875, -0.01806640625, 0.1279296875, 0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.4000773907418237, -1.268286648446229]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[computer, parts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>INTEL CORPORATION</td>\n",
       "      <td>[intel, corporation]</td>\n",
       "      <td>intel corporation</td>\n",
       "      <td>[-0.09057617, -0.05618286, -0.047286987, 0.036...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.090576171875, -0.056182861328125, -0.04728...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.01506322581369444, -0.6966174861946703]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[intel, corporation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>INTEL CO</td>\n",
       "      <td>[intel, co]</td>\n",
       "      <td>intel co</td>\n",
       "      <td>[-0.12866211, -0.048858643, -0.07739258, -0.01...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.128662109375, -0.048858642578125, -0.07739...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.09258259492603038, -0.6886559717277149]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[intel, co]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ryland Group Inc.</td>\n",
       "      <td>[ryland, group, inc]</td>\n",
       "      <td>ryland group inc</td>\n",
       "      <td>[-0.048828125, -0.14892578, 0.11828613, 0.0244...</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.048828125, -0.14892578125, 0.1182861328125...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>[-1.5389946332875948, -1.3929259365761135]</td>\n",
       "      <td>cluster_4</td>\n",
       "      <td>[Ryland_Group, GROUP_INC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sabre Holdings Corp</td>\n",
       "      <td>[sabre, holdings, corp]</td>\n",
       "      <td>sabre holdings corp</td>\n",
       "      <td>[-0.06677246, -0.27148438, -0.20471191, 0.0195...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0667724609375, -0.271484375, -0.2047119140...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.7155866241668235, -1.4217536438064498]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[Sabre_Holdings, HOLDINGS_CORP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Safeco Corp</td>\n",
       "      <td>[safeco, corp]</td>\n",
       "      <td>safeco corp</td>\n",
       "      <td>[0.123291016, 0.1694336, 0.04345703, 0.2207031...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.123291015625, 0.16943359375, 0.04345703125,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.19705853624145972, -0.7178368262091196]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[safeco, corp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4CE0460D0G</td>\n",
       "      <td>[#, ce, #, #, #, #, d, #, g]</td>\n",
       "      <td># ce # # # # d # g</td>\n",
       "      <td>[-0.10530599, -0.11151123, 0.039208308, 0.0326...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.1053059920668602, -0.11151123046875, 0.039...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1.0622427355209747, 2.1556257093794957]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[#, ce, #, #, #, #, d, #, g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vero Beach, Florida</td>\n",
       "      <td>[vero, beach, florida]</td>\n",
       "      <td>vero beach florida</td>\n",
       "      <td>[0.13382976, -0.17040634, -0.14436848, 0.21211...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1338297575712204, -0.17040634155273438, -0....</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>[0.6725698534577436, -0.24615475538902323]</td>\n",
       "      <td>cluster_6</td>\n",
       "      <td>[Vero_Beach, beach, florida]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>WINE</td>\n",
       "      <td>[wine]</td>\n",
       "      <td>wine</td>\n",
       "      <td>[-0.17578125, -0.109375, -0.18945312, 0.15625,...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.17578125, -0.109375, -0.189453125, 0.15625...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.07667712800183232, -1.8678950763719238]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[wine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Microwave</td>\n",
       "      <td>[microwave]</td>\n",
       "      <td>microwave</td>\n",
       "      <td>[-0.30078125, -0.06689453, 0.075683594, 0.3242...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.30078125, -0.06689453125, 0.07568359375, 0...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1.182552850346409, -1.917395703649934]</td>\n",
       "      <td>cluster_4</td>\n",
       "      <td>[microwave]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Plastic container</td>\n",
       "      <td>[plastic, container]</td>\n",
       "      <td>plastic container</td>\n",
       "      <td>[0.0061950684, -0.00010347366, -0.015991211, 0...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.006195068359375, -0.00010347366333007812, -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.9166458013441726, -0.6516012762167295]</td>\n",
       "      <td>cluster_5</td>\n",
       "      <td>[Plastic_Container]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Europe</td>\n",
       "      <td>[europe]</td>\n",
       "      <td>europe</td>\n",
       "      <td>[-0.15429688, -0.080078125, 0.11328125, 0.4707...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.154296875, -0.080078125, 0.11328125, 0.470...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[3.606586025703825, 0.3872045168390986]</td>\n",
       "      <td>cluster_1</td>\n",
       "      <td>[europe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Canada</td>\n",
       "      <td>[canada]</td>\n",
       "      <td>canada</td>\n",
       "      <td>[-0.45507812, -0.21289062, -0.33398438, 0.3085...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.455078125, -0.212890625, -0.333984375, 0.3...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[3.637957039000884, 0.8178108769859223]</td>\n",
       "      <td>cluster_1</td>\n",
       "      <td>[canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HGU6UH3</td>\n",
       "      <td>[hgu, #, uh, #]</td>\n",
       "      <td>hgu # uh #</td>\n",
       "      <td>[-0.043518066, -0.14971924, 0.041534424, 0.066...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.04351806640625, -0.14971923828125, 0.04153...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1.1227530749083858, 2.1579019282676013]</td>\n",
       "      <td>cluster_3</td>\n",
       "      <td>[hgu, #, uh, #]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text  \\\n",
       "0              Marks and Spencers Ltd   \n",
       "1                         M&S Limited   \n",
       "2                      NVIDIA Ireland   \n",
       "3                     SLOUGH SE12 2XY   \n",
       "4       33 TIMBER YARD,LONDON, L1 8XY   \n",
       "5   44 CHINA ROAD, KOWLOON, HONG KONG   \n",
       "6                     XYZ 13423 / ILD   \n",
       "7                     ABC/ICL/20891NC   \n",
       "8                      HARDWOOD TABLE   \n",
       "9                      PLASTIC BOTTLE   \n",
       "10                             LONDON   \n",
       "11                          HONG KONG   \n",
       "12                               ASIA   \n",
       "13              JP Morgan & Chase Co.   \n",
       "14                         ICNAO02312   \n",
       "15                               TOYS   \n",
       "16  5 Time Square, New York, NY 10036   \n",
       "17                     COMPUTER PARTS   \n",
       "18                  INTEL CORPORATION   \n",
       "19                           INTEL CO   \n",
       "20                  Ryland Group Inc.   \n",
       "21                Sabre Holdings Corp   \n",
       "22                        Safeco Corp   \n",
       "23                         4CE0460D0G   \n",
       "24                Vero Beach, Florida   \n",
       "25                               WINE   \n",
       "26                          Microwave   \n",
       "27                  Plastic container   \n",
       "28                             Europe   \n",
       "29                             Canada   \n",
       "30                            HGU6UH3   \n",
       "\n",
       "                                        clean_token  \\\n",
       "0                       [marks, and, spencers, ltd]   \n",
       "1                                [m, &, s, limited]   \n",
       "2                                 [nvidia, ireland]   \n",
       "3                         [slough, se, #, #, #, xy]   \n",
       "4         [#, #, timber, yard, london, l, #, #, xy]   \n",
       "5          [#, #, china, road, kowloon, hong, kong]   \n",
       "6                         [xyz, #, #, #, #, #, ild]   \n",
       "7                       [abcicl, #, #, #, #, #, nc]   \n",
       "8                                 [hardwood, table]   \n",
       "9                                 [plastic, bottle]   \n",
       "10                                         [london]   \n",
       "11                                     [hong, kong]   \n",
       "12                                           [asia]   \n",
       "13                       [jp, morgan, &, chase, co]   \n",
       "14                           [icnao, #, #, #, #, #]   \n",
       "15                                           [toys]   \n",
       "16  [#, time, square, new, york, ny, #, #, #, #, #]   \n",
       "17                                [computer, parts]   \n",
       "18                             [intel, corporation]   \n",
       "19                                      [intel, co]   \n",
       "20                             [ryland, group, inc]   \n",
       "21                          [sabre, holdings, corp]   \n",
       "22                                   [safeco, corp]   \n",
       "23                     [#, ce, #, #, #, #, d, #, g]   \n",
       "24                           [vero, beach, florida]   \n",
       "25                                           [wine]   \n",
       "26                                      [microwave]   \n",
       "27                             [plastic, container]   \n",
       "28                                         [europe]   \n",
       "29                                         [canada]   \n",
       "30                                  [hgu, #, uh, #]   \n",
       "\n",
       "                           clean_string  \\\n",
       "0                marks and spencers ltd   \n",
       "1                         m & s limited   \n",
       "2                        nvidia ireland   \n",
       "3                    slough se # # # xy   \n",
       "4       # # timber yard london l # # xy   \n",
       "5      # # china road kowloon hong kong   \n",
       "6                     xyz # # # # # ild   \n",
       "7                   abcicl # # # # # nc   \n",
       "8                        hardwood table   \n",
       "9                        plastic bottle   \n",
       "10                               london   \n",
       "11                            hong kong   \n",
       "12                                 asia   \n",
       "13                 jp morgan & chase co   \n",
       "14                      icnao # # # # #   \n",
       "15                                 toys   \n",
       "16  # time square new york ny # # # # #   \n",
       "17                       computer parts   \n",
       "18                    intel corporation   \n",
       "19                             intel co   \n",
       "20                     ryland group inc   \n",
       "21                  sabre holdings corp   \n",
       "22                          safeco corp   \n",
       "23                   # ce # # # # d # g   \n",
       "24                   vero beach florida   \n",
       "25                                 wine   \n",
       "26                            microwave   \n",
       "27                    plastic container   \n",
       "28                               europe   \n",
       "29                               canada   \n",
       "30                           hgu # uh #   \n",
       "\n",
       "                                           vecter_300  word_count  char_count  \\\n",
       "0   [-0.081870556, -0.028320312, -0.05102539, 0.10...           4          19   \n",
       "1   [-0.15039062, 0.09075928, -0.11743164, 0.13623...           4          10   \n",
       "2   [0.01928711, -0.19091797, -0.053955078, 0.3242...           2          13   \n",
       "3   [-0.08087158, -0.079182945, 0.05058797, 0.0112...           6          13   \n",
       "4   [-0.053792316, -0.05820041, -0.040527344, 0.02...           9          23   \n",
       "5   [-0.029296875, -0.008544922, -0.027374268, 0.1...           7          26   \n",
       "6   [-0.03137207, -0.16071428, 0.038007464, 0.0290...           7          11   \n",
       "7   [-0.04889788, -0.19213867, 0.03993443, 0.04035...           7          13   \n",
       "8   [-0.06680298, 0.090270996, 0.015136719, 0.2207...           2          13   \n",
       "9   [-0.21679688, -0.18652344, -0.025756836, 0.041...           2          13   \n",
       "10  [-0.4609375, 0.027954102, -0.26757812, 0.41015...           1           6   \n",
       "11  [0.008300781, -0.018798828, -0.12451172, 0.046...           2           8   \n",
       "12  [-0.15332031, 0.03112793, -0.28710938, 0.28515...           1           4   \n",
       "13  [-0.11416016, 0.0953125, -0.14238282, 4.882812...           5          16   \n",
       "14  [-0.033447266, -0.21972656, 0.01940918, 0.0081...           6          10   \n",
       "15  [0.1484375, 0.17675781, 0.15527344, 0.38085938...           1           4   \n",
       "16  [-0.09442694, -0.09439616, -0.005909313, 0.031...          11          25   \n",
       "17  [0.123046875, -0.018066406, 0.12792969, 0.1962...           2          13   \n",
       "18  [-0.09057617, -0.05618286, -0.047286987, 0.036...           2          16   \n",
       "19  [-0.12866211, -0.048858643, -0.07739258, -0.01...           2           7   \n",
       "20  [-0.048828125, -0.14892578, 0.11828613, 0.0244...           3          14   \n",
       "21  [-0.06677246, -0.27148438, -0.20471191, 0.0195...           3          17   \n",
       "22  [0.123291016, 0.1694336, 0.04345703, 0.2207031...           2          10   \n",
       "23  [-0.10530599, -0.11151123, 0.039208308, 0.0326...           9          10   \n",
       "24  [0.13382976, -0.17040634, -0.14436848, 0.21211...           3          16   \n",
       "25  [-0.17578125, -0.109375, -0.18945312, 0.15625,...           1           4   \n",
       "26  [-0.30078125, -0.06689453, 0.075683594, 0.3242...           1           9   \n",
       "27  [0.0061950684, -0.00010347366, -0.015991211, 0...           2          16   \n",
       "28  [-0.15429688, -0.080078125, 0.11328125, 0.4707...           1           6   \n",
       "29  [-0.45507812, -0.21289062, -0.33398438, 0.3085...           1           6   \n",
       "30  [-0.043518066, -0.14971924, 0.041534424, 0.066...           4           7   \n",
       "\n",
       "    company_str                                 new_feature_concat  \\\n",
       "0             1  [-0.08187055587768555, -0.0283203125, -0.05102...   \n",
       "1             1  [-0.150390625, 0.09075927734375, -0.1174316406...   \n",
       "2             0  [0.019287109375, -0.19091796875, -0.0539550781...   \n",
       "3             0  [-0.08087158203125, -0.0791829451918602, 0.050...   \n",
       "4             0  [-0.0537923164665699, -0.0582004114985466, -0....   \n",
       "5             0  [-0.029296875, -0.008544921875, -0.02737426757...   \n",
       "6             0  [-0.0313720703125, -0.1607142835855484, 0.0380...   \n",
       "7             0  [-0.0488978810608387, -0.192138671875, 0.03993...   \n",
       "8             0  [-0.066802978515625, 0.09027099609375, 0.01513...   \n",
       "9             0  [-0.216796875, -0.1865234375, -0.0257568359375...   \n",
       "10            0  [-0.4609375, 0.0279541015625, -0.267578125, 0....   \n",
       "11            0  [0.00830078125, -0.018798828125, -0.1245117187...   \n",
       "12            0  [-0.1533203125, 0.0311279296875, -0.287109375,...   \n",
       "13            1  [-0.11416015774011612, 0.09531249850988388, -0...   \n",
       "14            0  [-0.033447265625, -0.2197265625, 0.01940917968...   \n",
       "15            0  [0.1484375, 0.1767578125, 0.1552734375, 0.3808...   \n",
       "16            0  [-0.09442693740129471, -0.09439615905284882, -...   \n",
       "17            0  [0.123046875, -0.01806640625, 0.1279296875, 0....   \n",
       "18            1  [-0.090576171875, -0.056182861328125, -0.04728...   \n",
       "19            1  [-0.128662109375, -0.048858642578125, -0.07739...   \n",
       "20            1  [-0.048828125, -0.14892578125, 0.1182861328125...   \n",
       "21            1  [-0.0667724609375, -0.271484375, -0.2047119140...   \n",
       "22            1  [0.123291015625, 0.16943359375, 0.04345703125,...   \n",
       "23            0  [-0.1053059920668602, -0.11151123046875, 0.039...   \n",
       "24            0  [0.1338297575712204, -0.17040634155273438, -0....   \n",
       "25            0  [-0.17578125, -0.109375, -0.189453125, 0.15625...   \n",
       "26            0  [-0.30078125, -0.06689453125, 0.07568359375, 0...   \n",
       "27            0  [0.006195068359375, -0.00010347366333007812, -...   \n",
       "28            0  [-0.154296875, -0.080078125, 0.11328125, 0.470...   \n",
       "29            0  [-0.455078125, -0.212890625, -0.333984375, 0.3...   \n",
       "30            0  [-0.04351806640625, -0.14971923828125, 0.04153...   \n",
       "\n",
       "    digital_ratio  punctuation_ratio  \\\n",
       "0        0.000000           0.000000   \n",
       "1        0.000000           0.100000   \n",
       "2        0.000000           0.000000   \n",
       "3        0.230769           0.000000   \n",
       "4        0.160000           0.080000   \n",
       "5        0.071429           0.071429   \n",
       "6        0.416667           0.083333   \n",
       "7        0.333333           0.133333   \n",
       "8        0.000000           0.000000   \n",
       "9        0.000000           0.000000   \n",
       "10       0.000000           0.000000   \n",
       "11       0.000000           0.000000   \n",
       "12       0.000000           0.000000   \n",
       "13       0.000000           0.117647   \n",
       "14       0.500000           0.000000   \n",
       "15       0.000000           0.000000   \n",
       "16       0.222222           0.074074   \n",
       "17       0.000000           0.000000   \n",
       "18       0.000000           0.000000   \n",
       "19       0.000000           0.000000   \n",
       "20       0.000000           0.066667   \n",
       "21       0.000000           0.000000   \n",
       "22       0.000000           0.000000   \n",
       "23       0.600000           0.000000   \n",
       "24       0.000000           0.058824   \n",
       "25       0.000000           0.000000   \n",
       "26       0.000000           0.000000   \n",
       "27       0.000000           0.000000   \n",
       "28       0.000000           0.000000   \n",
       "29       0.000000           0.000000   \n",
       "30       0.285714           0.000000   \n",
       "\n",
       "                                             2D hierarchy_label  \\\n",
       "0   [-0.21785738628969087, -0.6526475067830879]       cluster_5   \n",
       "1    [-0.5241411593227774, -0.3759396544394854]       cluster_5   \n",
       "2        [2.14325646307336, 0.7570817600426596]       cluster_2   \n",
       "3      [-0.7947209999704078, 1.450827102862683]       cluster_3   \n",
       "4     [-0.6639117274922118, 1.2593845789605327]       cluster_3   \n",
       "5     [-0.4829997613936409, 0.1633026370875465]       cluster_5   \n",
       "6      [-1.1662113068773892, 2.038164207474194]       cluster_3   \n",
       "7      [-1.3660956376220394, 2.646343018784372]       cluster_3   \n",
       "8    [-0.7936115213264696, -1.1702179552925702]       cluster_5   \n",
       "9    [-1.0395265178842157, -0.9673859940555555]       cluster_5   \n",
       "10      [3.520168681022658, 0.5717443397363491]       cluster_1   \n",
       "11    [0.4909592109840397, -1.3710826802831357]       cluster_5   \n",
       "12    [3.7243591171218737, 0.09884199626703945]       cluster_1   \n",
       "13   [-0.2773023301133141, -0.7386944469461296]       cluster_5   \n",
       "14     [-1.6535629629423227, 2.806075337716592]       cluster_3   \n",
       "15   [-0.7848783343063905, -2.7075351850596334]       cluster_4   \n",
       "16    [-0.8641564055279805, 1.5423187370434204]       cluster_3   \n",
       "17    [-0.4000773907418237, -1.268286648446229]       cluster_5   \n",
       "18  [-0.01506322581369444, -0.6966174861946703]       cluster_5   \n",
       "19  [-0.09258259492603038, -0.6886559717277149]       cluster_5   \n",
       "20   [-1.5389946332875948, -1.3929259365761135]       cluster_4   \n",
       "21   [-0.7155866241668235, -1.4217536438064498]       cluster_5   \n",
       "22  [-0.19705853624145972, -0.7178368262091196]       cluster_5   \n",
       "23    [-1.0622427355209747, 2.1556257093794957]       cluster_3   \n",
       "24   [0.6725698534577436, -0.24615475538902323]       cluster_6   \n",
       "25   [0.07667712800183232, -1.8678950763719238]       cluster_5   \n",
       "26     [-1.182552850346409, -1.917395703649934]       cluster_4   \n",
       "27   [-0.9166458013441726, -0.6516012762167295]       cluster_5   \n",
       "28      [3.606586025703825, 0.3872045168390986]       cluster_1   \n",
       "29      [3.637957039000884, 0.8178108769859223]       cluster_1   \n",
       "30    [-1.1227530749083858, 2.1579019282676013]       cluster_3   \n",
       "\n",
       "                                  clean_token_bi_gram  \n",
       "0                         [marks, and, spencers, ltd]  \n",
       "1                                  [m, &, s, limited]  \n",
       "2                                   [nvidia, ireland]  \n",
       "3                           [slough, se, #, #, #, xy]  \n",
       "4           [#, #, timber, yard, london, l, #, #, xy]  \n",
       "5             [#, #, china, road, kowloon, Hong_Kong]  \n",
       "6                           [xyz, #, #, #, #, #, ild]  \n",
       "7                         [abcicl, #, #, #, #, #, nc]  \n",
       "8                                   [hardwood, table]  \n",
       "9                                    [Plastic_Bottle]  \n",
       "10                                           [london]  \n",
       "11                                        [Hong_Kong]  \n",
       "12                                             [asia]  \n",
       "13                  [JP_Morgan, morgan, &, chase, co]  \n",
       "14                             [icnao, #, #, #, #, #]  \n",
       "15                                             [toys]  \n",
       "16  [#, time, square, New_York, york, ny, #, #, #,...  \n",
       "17                                  [computer, parts]  \n",
       "18                               [intel, corporation]  \n",
       "19                                        [intel, co]  \n",
       "20                          [Ryland_Group, GROUP_INC]  \n",
       "21                    [Sabre_Holdings, HOLDINGS_CORP]  \n",
       "22                                     [safeco, corp]  \n",
       "23                       [#, ce, #, #, #, #, d, #, g]  \n",
       "24                       [Vero_Beach, beach, florida]  \n",
       "25                                             [wine]  \n",
       "26                                        [microwave]  \n",
       "27                                [Plastic_Container]  \n",
       "28                                           [europe]  \n",
       "29                                           [canada]  \n",
       "30                                    [hgu, #, uh, #]  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curious to see the clusters in a more mathematical way\n",
    "<b> (Though hierarchy can't really be applied to massive data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clusters(df, cluster_col):\n",
    "    cluster_dict = df.groupby(cluster_col)['text'].apply(list).to_dict()\n",
    "    for k, v, in cluster_dict.items():\n",
    "        print (k, v)\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z = hierarchy.linkage(vals_pca, method = \"average\", metric = 'euclidean')\n",
    "plt.figure()\n",
    "dn = hierarchy.dendrogram(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent hierarchy graph, looks like 1.5 would be a good threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.5\n",
    "C = hierarchy.fcluster(Z, threshold, criterion=\"distance\")\n",
    "labels = (C).tolist()\n",
    "labels = ['cluster_'+str(s) for s in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_1 ['LONDON', 'ASIA', 'Europe', 'Canada']\n",
      "\n",
      "cluster_2 ['NVIDIA Ireland']\n",
      "\n",
      "cluster_3 ['SLOUGH SE12 2XY', '33 TIMBER YARD,LONDON, L1 8XY', 'XYZ 13423 / ILD', 'ABC/ICL/20891NC', 'ICNAO02312', '5 Time Square, New York, NY 10036', '4CE0460D0G', 'HGU6UH3']\n",
      "\n",
      "cluster_4 ['TOYS', 'Ryland Group Inc.', 'Microwave']\n",
      "\n",
      "cluster_5 ['Marks and Spencers Ltd', 'M&S Limited', '44 CHINA ROAD, KOWLOON, HONG KONG', 'HARDWOOD TABLE', 'PLASTIC BOTTLE', 'HONG KONG', 'JP Morgan & Chase Co.', 'COMPUTER PARTS', 'INTEL CORPORATION', 'INTEL CO', 'Sabre Holdings Corp', 'Safeco Corp', 'Vero Beach, Florida', 'WINE', 'Plastic container']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['hierarchy_label'] = labels\n",
    "print_clusters(df, 'hierarchy_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceeding with these features for the second part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique entity recognition (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as D\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "import pickle as pk\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = pd.read_csv('../data/traning_v4.csv') # test string INTEL CORPORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = labeled.dropna()\n",
    "labeled = labeled.drop_duplicates()\n",
    "labeled = shuffle(labeled).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = labeled.head(2000).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess - input dataset with str_1 and str_2\n",
    "def concat_features(row, col): \n",
    "    concat_list = np.array([row[col+'_word_count'], row[col+'_char_count'], row[col+'_company_flag'], row[col+'_digit_ratio']])\n",
    "    new_concat_list = np.append(row[col+'_vector_300'], concat_list)\n",
    "    return new_concat_list\n",
    "\n",
    "# return a list of characteristics features, input data with str_1 and str2 \n",
    "def get_char_features_labled(updated_df): \n",
    "    return_list = []\n",
    "    for idx, row in updated_df.iterrows(): \n",
    "        append_list = []\n",
    "        append_list.append(row['str_1_word_count']-row['str_2_word_count']) # word count difference\n",
    "        append_list.append(row['str_1_char_count']-row['str_2_char_count']) # character count difference\n",
    "        append_list.append(len(set(row['str_1_token']).intersection(set(row['str_2_token'])))) # common word\n",
    "        append_list.append(fuzz.ratio(row['str_1_clean_string'], row['str_2_clean_string'])) # fuzz ratio\n",
    "        append_list.append(fuzz.partial_ratio(row['str_1_clean_string'], row['str_2_clean_string'])) # fuzz partical\n",
    "        append_list.append(fuzz.token_set_ratio(row['str_1_clean_string'], row['str_2_clean_string'])) # fuzz token set\n",
    "        append_list.append(fuzz.partial_token_sort_ratio(row['str_1_clean_string'], row['str_2_clean_string']))\n",
    "        append_list.append(fuzz.token_sort_ratio(row['str_1_clean_string'], row['str_2_clean_string']))\n",
    "        append_list.append(w2v.wmdistance(row['str_1_clean_string'], row['str_2_clean_string']))\n",
    "        append_list.append(w2v_norm.wmdistance(row['str_1_clean_string'], row['str_2_clean_string']))\n",
    "        return_list.append(append_list)\n",
    "    return return_list\n",
    "\n",
    "# return a list of distance features, input data with str_1 and str2 after normalization \n",
    "def get_dist_features_labeled(updated_df):\n",
    "    v1 = np.array(updated_df['str_1_feature_concat'].tolist())\n",
    "    v2 = np.array(updated_df['str_2_feature_concat'].tolist())\n",
    "    return_list = []\n",
    "    for i in range (v1.shape[0]): \n",
    "        append_list = []\n",
    "        if v1[i].sum()==0 or v2[i].sum()==0: \n",
    "            print (updated_df.iat[i,0])\n",
    "        append_list.append(D.cosine(v1[i], v2[i]))\n",
    "        append_list.append(D.euclidean(v1[i], v2[i]))\n",
    "        append_list.append(D.cityblock(v1[i], v2[i]))\n",
    "        append_list.append(D.minkowski(v1[i], v2[i]))\n",
    "        append_list.append(D.braycurtis(v1[i], v2[i]))\n",
    "        append_list.append(D.canberra(v1[i], v2[i]))\n",
    "        return_list.append(append_list)\n",
    "    return return_list\n",
    "\n",
    "# concat and normlize X \n",
    "def process_X(c_v, d_v): \n",
    "    return_list = []\n",
    "    for i in range(len(c_v)): \n",
    "        return_list.append(c_v[i]+d_v[i])\n",
    "    mat = np.array(return_list)\n",
    "    mat = scale_mat(mat, 'MinMax')\n",
    "    return mat\n",
    "\n",
    "def process_df(labeled_df):\n",
    "    for col in ['str_1', 'str_2']: \n",
    "        labeled_df[col+'_token'] = labeled_df[col].apply(lambda x: get_tokens(x))\n",
    "        labeled_df[col+'_clean_string'] = labeled_df[col+'_token'].apply(lambda x: ' '.join(x))\n",
    "        labeled_df[col+'_clean_token_bi_gram'] = labeled_df[col+'_token'].apply(lambda x: get_bi_gram(x))\n",
    "        labeled_df[col+'_vector_300'] = labeled_df[col+'_clean_token_bi_gram'].apply(lambda x: get_vector(x))\n",
    "        labeled_df[col+'_word_count'] = labeled_df[col+'_token'].apply(lambda x: get_word_cnt(x))\n",
    "        labeled_df[col+'_char_count'] = labeled_df[col+'_token'].apply(lambda x: get_char_cnt(x))\n",
    "        labeled_df[col+'_company_flag'] = labeled_df[col+'_token'].apply(lambda x: get_company_flag(x))\n",
    "        labeled_df[col+'_digit_ratio'] = labeled_df[col].apply(lambda x: get_digits_ratio(x))\n",
    "        #labeled_df[col+'_punctuation_ratio'] = labeled_df[col].apply(lambda x: get_punc_ratio(x))\n",
    "        labeled_df[col+'_feature_concat'] = labeled_df.apply(lambda row: concat_features(row, col), axis = 1)\n",
    "        #print (col+' DONE')\n",
    "    #print ('String features DONE.')\n",
    "    char_features = get_char_features_labled(labeled_df)\n",
    "    #print ('Characteristics features DONE.')\n",
    "    dist_features = get_dist_features_labeled(labeled_df)\n",
    "    #print ('Distance features DONE. ')\n",
    "    # Got features, now concat and normalize\n",
    "    labeled_df['X'] = process_X(char_features, dist_features).tolist()\n",
    "    return labeled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and Y \n",
    "start_time = time.time()\n",
    "labeled_df = process_df(labeled)\n",
    "print ('Data processed. Time taken: ', time.time()-start_time)\n",
    "X_train = np.array(labeled_df['X'].tolist())\n",
    "Y_train = labeled_df['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.1, 1, 10, 100]\n",
    "    gammas = [0.1, 1, 10, 100]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    return_param = grid_search.best_params_\n",
    "    return return_param\n",
    "param = svc_param_selection(X_train, Y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf_tree = tree.DecisionTreeClassifier()\n",
    "clf_tree = clf_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "clf_gnb = gnb.fit(X_train, Y_train)\n",
    "clf_pf = gnb.partial_fit(X_train, Y_train, np.unique(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Model done. Time taken:  0.015563011169433594\n"
     ]
    }
   ],
   "source": [
    "# Train a simple SVM \n",
    "start_time = time.time()\n",
    "print ('Training...')\n",
    "clf = svm.SVC(**param)\n",
    "clf.fit(X_train, Y_train)\n",
    "print ('Model done. Time taken: ', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pk.dump( clf, open( \"../data/svm_1.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the classifier with new strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current data points \n",
    "data = pd.read_excel('../data/Book1.xlsx')\n",
    "data_inventory = data['str_1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING_STR_TRUE: There should be an equivalent entity in the data inventory \n",
    "TESTING_STR_TRUE = ['INTEL CO', 'IBM Corporation', 'Shanghai, China', 'Allentown, PA, USA',\\\n",
    "                    'Seoul, SK', 'GYU671A3', 'M&S Limited', 'Pepsico', '5 Time Sqaure, NY, NY']\n",
    "# TESTING_STR_FALSE: They should NOT be groupped with any entity \n",
    "TESTING_STR_FALSE = ['Apple Inc.', 'Sunrise Corporation', 'Palm Beach, FL', 'Toronto, Canada', \\\n",
    "                     'Austin, TX', 'PwC LLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labeled['str_1'].str.contains('Allentown').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTEL CO : ['INTEL CORPORATION']\n",
      "IBM Corporation : ['INTEL CORPORATION']\n",
      "Shanghai, China : ['Pepsi Co.', 'RYLAND GROUP INC.', 'ICNAO02312']\n",
      "Allentown, PA, USA : ['Allentown, Pennsylvania']\n",
      "Seoul, SK : ['Los Angeles, CA', 'Ernst & Young LLP']\n",
      "GYU671A3 : ['ICNAO02312']\n",
      "M&S Limited : ['Marks and Spencers Ltd']\n",
      "Pepsico : ['Pepsi Co.']\n",
      "5 Time Sqaure, NY, NY : []\n"
     ]
    }
   ],
   "source": [
    "print_res(TESTING_STR_TRUE, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. : ['Pepsi Co.', 'Marks and Spencers Ltd', 'Los Angeles, CA', 'INTEL CORPORATION', 'Allentown, Pennsylvania']\n",
      "Sunrise Corporation : ['INTEL CORPORATION']\n",
      "Palm Beach, FL : ['VERO BEACH, FLORIDA']\n",
      "Toronto, Canada : ['INTEL CORPORATION']\n",
      "Austin, TX : ['INTEL CORPORATION']\n",
      "PwC LLP : []\n"
     ]
    }
   ],
   "source": [
    "print_res(TESTING_STR_FALSE, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30000000000000004,\n",
       " 0.4545454545454546,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.7826086956521738,\n",
       " 0.5412638369874339,\n",
       " 0.5146780440508457,\n",
       " 0.0073153237881900535,\n",
       " 0.315499423079975,\n",
       " 0.18187387299711066,\n",
       " 0.315499423079975,\n",
       " 0.3534489005108258,\n",
       " 0.5820665066861355,\n",
       " 0.3684210526315789]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[16, 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(testing_list, model): \n",
    "    for testing_str in testing_list: \n",
    "        new_df = pd.DataFrame({'str_1': data_inventory.tolist()})\n",
    "        new_df['str_2'] = testing_str\n",
    "        new_df = process_df(new_df)\n",
    "        X_test = np.array(new_df['X'].tolist())\n",
    "        P = model.predict(X_test)\n",
    "        new_df['predicted'] = P.tolist()\n",
    "        entity_list = new_df[new_df.predicted==1]['str_1'].tolist()\n",
    "        print (testing_str, ':', entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTEL CO : ['Pepsi Co.', 'INTEL CORPORATION']\n",
      "IBM Corporation : ['INTEL CORPORATION']\n",
      "Shanghai, China : ['Pepsi Co.', 'United States of America', 'VERO BEACH, FLORIDA', 'Los Angeles, CA', 'RYLAND GROUP INC.', 'INTEL CORPORATION', '44 CHINA ROAD, KOWLOON, HONG KONG']\n",
      "Allentown, PA, USA : ['Allentown, Pennsylvania']\n",
      "Seoul, SK : ['Pepsi Co.', 'Los Angeles, CA', 'RYLAND GROUP INC.', 'Ernst & Young LLP']\n",
      "GYU671A3 : ['5 Time Sqaure, New York, NY 10036', '44 CHINA ROAD, KOWLOON, HONG KONG', 'ICNAO02312']\n",
      "M&S Limited : ['Marks and Spencers Ltd', 'Los Angeles, CA', 'Ernst & Young LLP']\n",
      "Pepsico : ['Pepsi Co.']\n",
      "5 Time Sqaure, NY, NY : ['5 Time Sqaure, New York, NY 10036']\n"
     ]
    }
   ],
   "source": [
    "for testing_str in TESTING_STR_TRUE: \n",
    "    new_df = pd.DataFrame({'str_1': data_inventory.tolist()})\n",
    "    new_df['str_2'] = testing_str\n",
    "    new_df = process_df(new_df)\n",
    "    X_test = np.array(new_df['X'].tolist())\n",
    "    P = clf_pf.predict(X_test)\n",
    "    new_df['clf'] = P.tolist()\n",
    "    entity_list = new_df[new_df.clf==1]['str_1'].tolist()\n",
    "    print (testing_str, ':', entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc. : ['Pepsi Co.', 'Marks and Spencers Ltd', 'Los Angeles, CA', 'RYLAND GROUP INC.', 'INTEL CORPORATION']\n",
      "Sunrise Corporation : ['INTEL CORPORATION']\n",
      "Palm Beach, FL : ['VERO BEACH, FLORIDA', 'Los Angeles, CA']\n",
      "Toronto, Canada : ['LONDON', 'VERO BEACH, FLORIDA', 'Marks and Spencers Ltd', 'Los Angeles, CA', 'INTEL CORPORATION']\n",
      "Austin, TX : ['INTEL CORPORATION']\n",
      "PwC LLP : ['Ernst & Young LLP']\n"
     ]
    }
   ],
   "source": [
    "for testing_str in TESTING_STR_FALSE: \n",
    "    new_df = pd.DataFrame({'str_1': data_inventory.tolist()})\n",
    "    new_df['str_2'] = testing_str\n",
    "    new_df = process_df(new_df)\n",
    "    X_test = np.array(new_df['X'].tolist())\n",
    "    P = clf_pf.predict(X_test)\n",
    "    new_df['clf'] = P.tolist()\n",
    "    entity_list = new_df[new_df.clf==1]['str_1'].tolist()\n",
    "    print (testing_str, ':', entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21889, 17)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp - Preprocess and get vector features (303,), return dictionary \n",
    "def get_feature_vector_303(string_input): \n",
    "    new_string_dict = { i : '' for i in df.columns}\n",
    "    token = get_tokens(string_input)\n",
    "    word_vec_google = get_vector(token)\n",
    "    word_cnt = get_word_cnt(token)\n",
    "    char_cnt = get_char_cnt(token)\n",
    "    com_flag = get_company_flag(token)\n",
    "    extra_features = np.array([word_cnt, char_cnt, com_flag])\n",
    "    v = np.append(word_vec_google, extra_features)\n",
    "    \n",
    "    new_string_dict['text'] = string_input\n",
    "    new_string_dict['clean_token'] = token\n",
    "    new_string_dict['clean_string'] = ' '.join(token)\n",
    "    new_string_dict['vecter_300'] = word_vec_google\n",
    "    new_string_dict['word_count'] = word_cnt\n",
    "    new_string_dict['char_count'] = char_cnt\n",
    "    new_string_dict['company_str'] = com_flag\n",
    "    new_string_dict['new_feature_concat'] = v\n",
    "    #v = scale_mat(v.reshape(-1,1),'MinMax')\n",
    "    return new_string_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_for_df(df, scale_type): \n",
    "    df_array = np.array(df['new_feature_concat'].tolist())\n",
    "    df_array = scale_mat(df_array,scale_type)\n",
    "    return df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_token</th>\n",
       "      <th>vecter_300</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>company_str</th>\n",
       "      <th>new_feature_concat</th>\n",
       "      <th>2D</th>\n",
       "      <th>clean_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marks and Spencers Ltd</td>\n",
       "      <td>[marks, and, spencers, ltd]</td>\n",
       "      <td>[-0.081870556, -0.028320312, -0.05102539, 0.10...</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.08187055587768555, -0.0283203125, -0.05102...</td>\n",
       "      <td>[-0.3339800956502091, -0.35841218689219334]</td>\n",
       "      <td>marks and spencers ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M&amp;S Limited</td>\n",
       "      <td>[m, &amp;, s, limited]</td>\n",
       "      <td>[-0.15039062, 0.09075928, -0.11743164, 0.13623...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.150390625, 0.09075927734375, -0.1174316406...</td>\n",
       "      <td>[-0.5162413962301977, -0.026243635885206534]</td>\n",
       "      <td>m &amp; s limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text                  clean_token  \\\n",
       "0  Marks and Spencers Ltd  [marks, and, spencers, ltd]   \n",
       "1             M&S Limited           [m, &, s, limited]   \n",
       "\n",
       "                                          vecter_300  word_count  char_count  \\\n",
       "0  [-0.081870556, -0.028320312, -0.05102539, 0.10...           4          19   \n",
       "1  [-0.15039062, 0.09075928, -0.11743164, 0.13623...           4          10   \n",
       "\n",
       "   company_str                                 new_feature_concat  \\\n",
       "0            1  [-0.08187055587768555, -0.0283203125, -0.05102...   \n",
       "1            1  [-0.150390625, 0.09075927734375, -0.1174316406...   \n",
       "\n",
       "                                             2D            clean_string  \n",
       "0   [-0.3339800956502091, -0.35841218689219334]  marks and spencers ltd  \n",
       "1  [-0.5162413962301977, -0.026243635885206534]           m & s limited  "
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'London United Kingdom'\n",
    "test_dict = get_feature_vector_303(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(test_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list of characteristics features\n",
    "def get_char_features(updated_df, new_string_dict): \n",
    "    return_list = []\n",
    "    for idx, row in updated_df.iterrows(): \n",
    "        append_list = []\n",
    "        append_list.append(row['word_count']-new_string_dict['word_count']) # word count difference\n",
    "        append_list.append(row['char_count']-new_string_dict['char_count']) # character count difference\n",
    "        append_list.append(len(set(row['clean_token']).intersection(set(new_string_dict['clean_token'])))) # common word\n",
    "        append_list.append(fuzz.ratio(row['clean_string'], new_string_dict['clean_string'])) # fuzz ratio\n",
    "        append_list.append(fuzz.partial_ratio(row['clean_string'], new_string_dict['clean_string'])) # fuzz partical\n",
    "        append_list.append(fuzz.token_set_ratio(row['clean_string'], new_string_dict['clean_string'])) # fuzz token set\n",
    "        return_list.append(append_list)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_matrix = np.array(df['new_feature_concat'].tolist())\n",
    "vector_matrix = scale_mat(vector_matrix, 'MinMax')\n",
    "vals_pca = sklearn_pca.fit_transform(vector_matrix)\n",
    "df['2D'] = vals_pca.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return s list of distance features\n",
    "# input df after appeding the new string because need to do PCA \n",
    "def get_dist_features(updated_df): \n",
    "    new_vec = updated_df.tail(1)['2D'].to_numpy()[0]\n",
    "    old_vec = updated_df['2D']\n",
    "    return_list = []\n",
    "    for v in old_vec: \n",
    "        #print (updated_df.iat[i,0], i)\n",
    "        v = np.array(v)\n",
    "        append_list = []\n",
    "        append_list.append(D.cosine(v, new_vec))\n",
    "        append_list.append(D.euclidean(v, new_vec))\n",
    "        append_list.append(D.cityblock(v, new_vec))\n",
    "        append_list.append(D.minkowski(v, new_vec))\n",
    "        return_list.append(append_list)\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_v = get_char_features(df, test_dict)\n",
    "dist_v = get_dist_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat and normlize X \n",
    "def process_X(c_v, d_v): \n",
    "    return_list = []\n",
    "    for i in range(len(c_v)): \n",
    "        return_list.append(c_v[i]+d_v[i])\n",
    "    mat = np.array(return_list)\n",
    "    mat = scale_mat(mat, 'MinMax')\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update training df\n",
    "train_df = pd.DataFrame(columns = ['str_1', 'str_2', 'X', 'Y'])\n",
    "train_df['str_1'] = df['text']\n",
    "train_df['str_2'] = test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_X(char_v, dist_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 9), (34, 4))"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['X'] = X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label data\n",
    "train_df['Y'] = 0\n",
    "train_df.iat[10,3] = 1\n",
    "train_df.iat[33,3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_2 = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_1 = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = pd.concat([train_df_1, train_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_train['X'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 10)"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 5)"
      ]
     },
     "execution_count": 1035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 10)\n"
     ]
    }
   ],
   "source": [
    "# try out the classifier \n",
    "try_string = 'vb, florida'\n",
    "try_dict = get_feature_vector_303(try_string)\n",
    "try_df = df.append(try_dict, ignore_index=True)\n",
    "\n",
    "#vector_matrix = np.array(try_df['new_feature_concat'].tolist())\n",
    "#vector_matrix = scale_mat(vector_matrix, 'MinMax')\n",
    "vector_matrix = scaler_for_df(try_df, 'MinMax')\n",
    "vals_pca = sklearn_pca.fit_transform(vector_matrix)\n",
    "\n",
    "try_df['2D'] = vals_pca.tolist()\n",
    "try_char_v = get_char_features(try_df, test_dict)\n",
    "try_dist_v = get_dist_features(try_df)\n",
    "try_X = process_X(try_char_v, try_dist_v)\n",
    "\n",
    "print (try_X.shape)\n",
    "\n",
    "new_train = pd.DataFrame()\n",
    "new_train['str_1'] = try_df['text']\n",
    "new_train['str_2'] = try_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = clf.predict(try_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train['clf'] = P.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor idx, row in my_df.iterrows(): \\n    my_dict = row.to_dict()\\n    character_list = []\\n    character_list.append(my_dict['word_cnt']-test_w_cnt) \\n    character_list.append(my_dict['char_cnt']-test_c_cnt) \\n    character_list.append(len(set(my_dict['clean_token']).intersection(set(test_token)))) # number of common word\\n    character_list.append(fuzz.ratio(my_dict['clean_string'], test_clean_string)) # fuzz ratio\\n    character_list.append(fuzz.partial_ratio(my_dict['clean_string'], test_clean_string)) # fuzz partical\\n    character_list.append(fuzz.token_set_ratio(my_dict['clean_string'], test_clean_string))\\n    character_list.append(fuzz.token_sort_ratio(my_dict['clean_string'], test_clean_string))\\n    character_list.append(fuzz.partial_token_set_ratio(my_dict['clean_string'], test_clean_string))\\n    character_list.append(fuzz.partial_token_sort_ratio(my_dict['clean_string'], test_clean_string))\\n    print (character_list)\\n\""
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for idx, row in my_df.iterrows(): \n",
    "    my_dict = row.to_dict()\n",
    "    character_list = []\n",
    "    character_list.append(my_dict['word_cnt']-test_w_cnt) \n",
    "    character_list.append(my_dict['char_cnt']-test_c_cnt) \n",
    "    character_list.append(len(set(my_dict['clean_token']).intersection(set(test_token)))) # number of common word\n",
    "    character_list.append(fuzz.ratio(my_dict['clean_string'], test_clean_string)) # fuzz ratio\n",
    "    character_list.append(fuzz.partial_ratio(my_dict['clean_string'], test_clean_string)) # fuzz partical\n",
    "    character_list.append(fuzz.token_set_ratio(my_dict['clean_string'], test_clean_string))\n",
    "    character_list.append(fuzz.token_sort_ratio(my_dict['clean_string'], test_clean_string))\n",
    "    character_list.append(fuzz.partial_token_set_ratio(my_dict['clean_string'], test_clean_string))\n",
    "    character_list.append(fuzz.partial_token_sort_ratio(my_dict['clean_string'], test_clean_string))\n",
    "    print (character_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a matrix of all kinds of distances \n",
    "def get_all_dist(v1, v2): \n",
    "    dist_list = []\n",
    "    dist_list.append(D.cosine(v1, v2))\n",
    "    dist_list.append(D.euclidean((v1, v2)))\n",
    "    return np.array(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.018331223903671368"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cosine_dist(init_vector, test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = df.iloc[0,3]\n",
    "b = df.iloc[1,3]\n",
    "cos_sim = dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627565141838561"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "result = 1-spatial.distance.cosine(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (w2v.distance('corporation', 'co'))\n",
    "print (w2v.wmdistance('corporation', 'co'))\n",
    "print (w2v_norm.distance('corporation', 'co'))\n",
    "print (w2v_norm.wmdistance('corporation', 'co'))\n",
    "'''\n",
    "def compute_similarity(s1, s2):\n",
    "    return 1.0 - (0.01 * max(fuzz.ratio(s1, s2),fuzz.token_sort_ratio(s1, s2),fuzz.token_set_ratio(s1, s2)))\n",
    "compute_similarity('INTELCORPORATION', 'INTELCO')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add distance \n",
    "def get_distance(v1, v2): \n",
    "    return w2v.distance(a, b)\n",
    "\n",
    "# add Word Mover's Distance\n",
    "def get_WMD(v1, v2): \n",
    "    return w2v_norm.wmdistance(a, b)\n",
    "\n",
    "def get_word_delta(tokens_1, tokens_2): \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_metric(a, b):\n",
    "    sim = np.isnan(dot(a, b)/(norm(a)*norm(b)))\n",
    "    if sim == False:\n",
    "        return dot(a, b)/(norm(a)*norm(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
